{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/zhongdjgmailcom/dl4c-content-and-progress-mgt-doc?scriptVersionId=128884959\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Lesson 1 Getting started\n\n## Main\n- [x]  [Guidence Page](https://course.fast.ai/Lessons/lesson1.html)\n- [x] [Video Course](https://www.youtube.com/watch?v=8SF_h3xF3cE)\n\n## Resources\n- Kaggle notebooks for this lesson:\n  - [x] [Is it a bird? Creating a model from your own data](https://www.kaggle.com/code/zhongdjgmailcom/is-it-a-bird-creating-a-model-from-your-own-data/edit)\n  - [x] [Jupyter Notebook 101](https://www.kaggle.com/code/jhoward/jupyter-notebook-101)\n- Colab notebooks\n  - [ ] [is it a bird](https://colab.research.google.com/drive/1uL22iJaNAi6xss0TybWnPGDpSh_AYptL#scrollTo=VAP_a-iiTfqk)\n- The fastai book:\n  - [x] [Free notebook version](https://github.com/fastai/fastbook)\n  - [x] [Chapter 1 notebook](https://github.com/fastai/fastbook/blob/master/01_intro.ipynb)\n- [x] [Repo containing all lesson notebooks](https://github.com/fastai/course22)\n- [x] [Solutions to chapter 1 questions from the book](https://forums.fast.ai/t/fastbook-chapter-1-questionnaire-solutions-wiki/65647)\n\n\n\n## Links\n- How to learn - highly recommended books for fast.ai students\n  - [ ] Meta Learning\n  - [ ] A Mathematician’s Lament by Paul Lockhart\n  - [ ] Making Learning Whole by David Perkins\n- Jupyter\n  - [x] Presentations: [RISE](https://rise.readthedocs.io/en/stable/)\n    - [short demo](https://youtu.be/sXyFa_r1nxA)\n  - [x] Blogging: [Quarto](https://quarto.org/)\n  - [x] The notebooks used to create the [fastai library](https://github.com/fastai/fastai/tree/master/nbs)\n  - [ ] [nbdev](https://nbdev.fast.ai/) - the system we built to create Python libraries using Jupyter\n- [ ] [Fastai: A Layered API for Deep Learning paper: Information Journal or arxiv or fast.ai](https://www.mdpi.com/2078-2489/11/2/108)\n- [ ] [Dall-e 2 illustrations of Twitter bios](https://twitter.com/nickcammarata/status/1511861061988892675)\n- [ ] [timm: PyTorch Image Models](https://timm.fast.ai/)","metadata":{}},{"cell_type":"markdown","source":"# Lesson 2 Deployment\n\n## Main\n- [x] [Guidence Page](https://course.fast.ai/Lessons/lesson2.html)\n- [x] [Video Course](https://youtu.be/F4tvM4Vb3A0)\n\n> 注意：在动手本地执行 jupyter-lab 过程中有以下几个问题需要注意：\n> - 使用 conda 做本地开发隔离环境安装时，在当前时间(2023/03/30)使用 conda/mamba install -c fastch fastai 安装在4090显卡机型上会有几个问题\n>   - 无法安装正确的 python, torch, torchvision, 需要手动指定安装，参考[各软件包版本](https://reactive.feishu.cn/docx/B30Ddq55XoV0q8xG09Yct1HhnBf?from=from_copylink)\n>   - 无法找到 sympy 1.11.1, 暂时可以忽略，待上面的安装完可以直接安装 ```conda install -c fastchan fastai```\n> - 在大陆访问视频课程中的 duckduckgo.com 需要走代理，最好在 jupyter-lab 启动之前，设置完成 ```\n    export http_proxy=http://192.168.0.110:10809\n    export https_proxy=http://192.168.0.110:10809```\n> - 代理服务本身设置，要保证 duckduckgo.com 确实走了代理的路由。例如选择 Global 类似字样的选项，或者把 By Pass 的选项打勾暂时去掉\n\n## Resources\n- Notebook—saving a basic fastai model:\n  - [x] [Kaggle](https://www.kaggle.com/code/jhoward/saving-a-basic-fastai-model/notebook)\n  - [x] [Colab](https://colab.research.google.com/drive/1M-mzhZdFQ2XWBSbLCuKzrmLsm0aLEYxQ?usp=sharing#scrollTo=98d53c05)\n- [x] [Chapter 2 notebook](https://github.com/fastai/fastbook/blob/master/02_production.ipynb)\n  - Further Readings\n    - [ ] [AI Applications: Top 18 Artificial Intelligence Applications in 2023](https://www.simplilearn.com/tutorials/artificial-intelligence-tutorial/artificial-intelligence-applications)\n    - [ ] [GPT5下一代：即将到来的7种能力将改变人工智能和技术的未来](https://www.youtube.com/watch?v=CcnPatOYIgo)\n- [ ] Solutions to chapter 2 questions from the book\n\n## Links\n- [ ] [Gradio tutorial](https://www.tanishq.ai/blog/gradio_hf_spaces_tutorial) from @ilovescience\n- [x] [HF Spaces](https://huggingface.co/spaces)\n- [x] Installing a python environment\n  - [x] [fastsetup](https://github.com/fastai/fastsetup)\n  - [x] Windows: [WSL](https://learn.microsoft.com/en-us/windows/wsl/install) and [Terminal](https://apps.microsoft.com/store/detail/windows-terminal/9N0DX20HK701)\n- [ ] tinypets [github](https://github.com/fastai/tinypets) / [site](https://fastai.github.io/tinypets/)\n- [ ] tinypets fork [github](https://github.com/jph00/tinypets) / [site](https://jph00.github.io/tinypets/)","metadata":{}},{"cell_type":"markdown","source":"# Lesson 3 Neural Net Foundations\n\n## Main\n- [x] [Guide](https://course.fast.ai/Lessons/lesson3.html)\n- [x] [Video](https://youtu.be/hBBOjCiFcuo)\n\n## Resources\n- Notebooks for this lesson:\n    - [ ] [HuggingFace Spaces Pets repository](https://huggingface.co/spaces/jph00/pets/tree/main)\n    - [x] [Chapter 4 notebook: How des a neural net  work?](https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb)\n    - [x] [Which image models are best?](https://www.kaggle.com/code/jhoward/which-image-models-are-best/)\n    \n- Other resources for the lesson\n    - [x] [Titanic spreadsheet](https://github.com/fastai/course22/blob/master/xl/titanic.xlsx)\n    - [ ] [Solutions to Chapter4 questions](https://forums.fast.ai/t/fastbook-chapter-4-questionnaire-solutions-wiki/67253)\n    \n## Links from the lesson\n- [ ] [Know your pet](https://gettoknowyourpet.com/)\n- [x] [Lesson 0](https://www.youtube.com/watch?v=gGxe2mN3kAg)\n\n## Repeat\n- [x] [Lesson 3 概要笔记](https://www.kaggle.com/code/zhongdjgmailcom/notebookdc8950ecfe)","metadata":{}},{"cell_type":"markdown","source":"# Lesson 4 Natual Language Processing\n\n## Main\n- [x] [Guide](https://course.fast.ai/Lessons/lesson4.html)\n- [x] [Video Course](https://youtu.be/toUgBQv1BT8)\n\n## Resources\n- Notebooks\n  - [x] [Getting Started with NLP for absolute beginners](https://www.kaggle.com/code/zhongdjgmailcom/getting-started-with-nlp-for-absolute-beginners/edit)\n  - [x] [Iterate like a grandmaster!](https://www.kaggle.com/code/jhoward/iterate-like-a-grandmaster/)\n  - [x] [Lesson 10 of fastbook](https://www.kaggle.com/code/zhongdjgmailcom/nlp-deep-dive-rnn/)\n\n## Links\n- [ ] [Python for Data Analysis, 3E](https://wesmckinney.com/book/)\n- [ ] [Code for pydata-book](https://github.com/wesm/pydata-book/tree/3rd-edition)\n- [ ] [How (and why) to create a good validation set](https://www.fast.ai/posts/2017-11-13-validation-sets.html)\n- [ ] [Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/)\n\n## Repeat\n- [x] [Getting Started with NLP for absolute Beginners](https://www.kaggle.com/zhongdjgmailcom/nlp-transformer-showcase)\n- [x] [Iterate like a grandmaster!](https://www.kaggle.com/code/zhongdjgmailcom/iterate-like-a-master-local-pc)\n- [x] [Lesson 10 of fastbook](https://www.kaggle.com/zhongdjgmailcom/imdb-review-classfication)","metadata":{}},{"cell_type":"markdown","source":"### 关于 Data Exploration Analysis\n- 数据维度：数据集包含哪些列，每列包含哪些数据类型，每列数据类型占总数据量的比例等。可以使用 df.info() 来查看数据的概况。\n- 数据分布：各个特征的分布情况、数据的统计特征（比如平均数、方差、中位数、众数等）。可以使用 df.describe() 来查看数据的统计特征，使用直方图、密度图等可视化手段来展示特征分布。\n- 缺失值和异常值：对于缺失值和异常值需要进行特殊处理，因为它们会对数据分析和模型训练造成很大的影响。可以使用 df.isnull().sum() 来查看缺失值的数量，使用箱线图、散点图等可视化手段来查看异常值情况。\n- 相关性分析：各个特征之间的相关性分析，可以使用相关系数矩阵、热力图等可视化手段来展示。\n- 数据采样：如果数据不均衡或者数据量过大，我们需要进行采样或者降维处理。可以使用分层抽样或者随机采样来进行数据采样，使用主成分分析（PCA）等技术来进行数据降维。\n\nhttps://projector.tensorflow.org/\nhttp://jalammar.github.io/illustrated-transformer/\n\n有很多可视化的工具和方法可以帮助我们理解 NLP 模型的工作原理。以下是一些可视化工具和资源：\n\n- [Embedding Projector](https://projector.tensorflow.org/)：一个在线工具，可以帮助您可视化和探索嵌入空间中的单词向量。\n- [Transformer Visualization](http://jalammar.github.io/illustrated-transformer/)：一篇博客文章，介绍了 Transformer 模型的工作原理，并通过可视化展示了注意力机制的运作方式。\n- [BERTviz](https://colab.research.google.com/drive/1hXIQ77A4TYS4y3UthWF-Ci7V7vVUoxmQ?usp=sharing#scrollTo=-QnRteSLP0Hm)：一个可视化工具，可以帮助您理解 BERT 模型的工作原理，包括词级注意力和自注意力等。\n- [Attention in Long Short-Term Memory Networks](https://distill.pub/2016/augmented-rnns/)：一篇博客文章，介绍了长短时记忆网络（LSTM）中注意力的工作原理，并通过可视化展示了这些机制如何工作。\n\n这些工具和资源可以帮助您更好地理解 NLP 模型，并更好地了解它们的内部工作原理。","metadata":{}},{"cell_type":"markdown","source":"# Lesson 5 From-scratch Model\n\n## Main \n- [x] [Guide](https://course.fast.ai/Lessons/lesson5.html)\n- [x] [Video](https://youtu.be/_rXzeWq4C6w)\n\n## Resources\n- Notebooks for this lesson\n  - [x] [Linear model and neural net from scratch](https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch)\n  - [x] [Why you should use a framework](https://www.kaggle.com/code/jhoward/why-you-should-use-a-framework)\n  - [x] [How random forests really work](https://www.kaggle.com/code/jhoward/how-random-forests-really-work/)\n  - [x] [Chapter 4: MNist Basics](https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb)\n  - [x] [Chapter 9: Tabular Modeling Deep Dive](https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb)\n  \n## Links\n- [ ] [OneR paper: Very Simple Classification Rules Perform Well on Most Commonly Used Datasets](https://link.springer.com/article/10.1023/A:1022631118932)\n- Some great Titanic notebooks: \n  - [ ] [MEG Risdal: Exploring Survival on the Titanic](https://www.kaggle.com/code/mrisdal/exploring-survival-on-the-titanic)\n  - [ ] [Chris Deotte: Titanic WCG+XGBoost 0.84688](https://www.kaggle.com/code/cdeotte/titanic-wcg-xgboost-0-84688/notebook)\n  - [ ] [Oscar Takeshita: Divide and Conquer: 0.82296](https://www.kaggle.com/code/pliptor/divide-and-conquer-0-82296)\n  - [ ] [Chris Deotte: Titanic using Name only 0.81818](https://www.kaggle.com/code/cdeotte/titanic-using-name-only-0-81818/notebook)\n  \n## Repeat\n  - [x] [Linear model and neural net from scratch](https://www.kaggle.com/code/zhongdjgmailcom/clean-repeat-linear-model-and-nn-from-scratch)\n  - [x] [Why you should use a framework]()\n  - [x] [How random forests really work](https://www.kaggle.com/code/zhongdjgmailcom/clean-how-random-forest-really-work)\n  \n## 仍然比较困惑\n  - 在 Repeat 过程中，from-scratch 发现一些参数的细节，对表现影响差异很大\n     - [ ] 权重矩阵初始化过程中, torch.rand() 过后，经过额外处理，顾虑是什么？\n       - ```(torch.rand(all_layer_outs[i], all_layer_outs[i + 1]) - 0.3) / all_layer_outs[i + 1] * 4```\n       - ```torch.rand(size) - 0.5```\n       - ```torch.rand(size) * 0.1```\n     - [ ] 设计几层神经网络，每层多少个。这对最终表现影响也很大。比如在 titanic 生存预测例子中，如果使用深度网络，实际上只有4层的时候表现还行，2个中间隐藏层，表现等追平线性回归，正确率能达到82%；如果层数深了，就变得很差了，正确率也就50%左右\n     - [ ] 跑多少 epochs，learning rate 怎么设计？本文中 Jeremy 在线性回归(epochs = 18, lr = 100)，1隐藏层NN(lr = 20)，2隐藏层NN(lr = 4) 使用的参数都有差异。","metadata":{}},{"cell_type":"markdown","source":"# Lesson 6 Random Forest\n\n## Main \n- [x] [Guide](https://course.fast.ai/Lessons/lesson6.html)\n- [x] [Video](https://youtu.be/AdhG64NF76E)\n\n## Resources\n- Notebooks for this lesson\n  - [x] [Chapter 9: Tabular Modeling Deep Dive](https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb)\n  - [x] [How random forests really work](https://www.kaggle.com/code/jhoward/how-random-forests-really-work/)\n  - [ ] [First Steps: Road to the Top, Part 1](https://www.kaggle.com/code/jhoward/first-steps-road-to-the-top-part-1)\n  - [ ] [Small models: Road to the Top, Part 2](https://www.kaggle.com/code/jhoward/small-models-road-to-the-top-part-2)\n\n- Links from the lesson\n  - [ ] [How to explain gradient boosting](https://explained.ai/gradient-boosting/)\n  - [ ] [Statistical modeling: The two cultures](https://www.semanticscholar.org/paper/Statistical-modeling%3A-The-two-cultures-Breiman/e5df6bc6da5653ad98e754b08f63326c2e52b372)\n  \n## Repeat\n- [ ] [First Steps: Road to the Top, Part 1]()\n- [ ] [Small models: Road to the Top, Part 2]()","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}